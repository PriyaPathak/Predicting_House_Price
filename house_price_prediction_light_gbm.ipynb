{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing needed libraries\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n%matplotlib inline\n\ncol_list = ['#cc615c', '#6965a7', '#f1bdbf']\nsns.set_palette(col_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_zero_values_table(df):\n        zero_val = (df == 0.00).astype(int).sum(axis=0)\n        mis_val = df.isnull().sum()\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n        mz_table = mz_table.rename(\n        columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% of Total Values'})\n        mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n        mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] / len(df)\n        mz_table['Data Type'] = df.dtypes\n        mz_table = mz_table[\n            mz_table.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"      \n            \"There are \" + str(mz_table.shape[0]) +\n              \" columns that have missing values.\")\n#         mz_table.to_excel('D:/sampledata/missing_and_zero_values.xlsx', freeze_panes=(1,0), index = False)\n        return mz_table\n\nmissing_zero_values_table(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_zero_values_table(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping columns with more than 40% of missing values\ntrain = train.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'], axis=1)\ntest = test.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputing for null values\n#to impute the variables with median for numerical columns\ntrain = train.fillna(train['LotFrontage'].value_counts().index[0])\ntrain = train.fillna(train['GarageYrBlt'].value_counts().index[0])\ntrain = train.fillna(train['MasVnrArea'].value_counts().index[0])\n\n#to impute the variables with median for numerical columns\ntest = test.fillna(train['LotFrontage'].value_counts().index[0])\ntest = test.fillna(train['GarageYrBlt'].value_counts().index[0])\ntest = test.fillna(train['MasVnrArea'].value_counts().index[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for null values\n#(train.isna().sum()/len(train))*100\n#(test.isna().sum()/len(test))*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns[train.isnull().any()]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns[test.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no null values now in both train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total number of rows and columns\ntrain.shape\n# Rows containing duplicate data\nduplicate_rows_df = train[train.duplicated()]\n#print('number_of duplicate rows:'+ duplicate_rows_df.shape)\n#number of duplicate rows:  (989, 10)\nduplicate_rows_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total number of rows and columns\ntest.shape\n# Rows containing duplicate data\nduplicate_rows_df_test = test[test.duplicated()]\n#print('number_of duplicate rows:'+ duplicate_rows_df.shape)\n#number of duplicate rows:  (989, 10)\nduplicate_rows_df_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"thus there are no duplicate rows in the train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#changing the datatypes\ntrain.select_dtypes(include=['object']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.select_dtypes(include=['object']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.MSZoning.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## converting Categorical Data into proper forms except account_info\nlist1 =['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n       'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n       'PavedDrive', 'SaleType', 'SaleCondition']\n\nfor col in list1:\n    train[col] = train[col].astype('category')\n\n### from category to int labels\nfor col in list1:\n    train[col] = train[col].cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## converting Categorical Data into proper forms except account_info\nlist1 =['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n       'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n       'PavedDrive', 'SaleType', 'SaleCondition']\n\nfor col in list1:\n    test[col] = test[col].astype('category')\n\n### from category to int labels\nfor col in list1:\n    test[col] = test[col].cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#viewing the dataset with the help of PROFILER\n#import pandas_profiling\n\n#pandas_profiling.ProfileReport(train)\n#pandas_profiling.ProfileReport(test)\n\n#extracting profiler report in html \n#profile1 = pandas_profiling.ProfileReport(master_data_final)\n#profile1.to_file(outputfile=\"Trade_Report_India.html\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train[['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n       'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageFinish',\n       'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive',\n       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n       'SaleCondition']]\ny= train[['SalePrice']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature importance\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#from sklearn.datasets import make_classification\nfrom sklearn.ensemble import ExtraTreesRegressor\n\n# Build a forest and compute the feature importances\nforest = ExtraTreesRegressor(n_estimators=250,random_state=0)\n\nforest.fit(X, y)\nimportances = forest.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(0,20):\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n\n\n# Plot the feature importances of the forest\nfeat_importances = pd.Series(importances, index=X.columns)\nfeat_importances.nlargest(20).plot(kind='barh',label=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train[['BedroomAbvGr', 'GarageType','CentralAir','LotArea','YearRemodAdd','TotRmsAbvGrd','BsmtFinSF1',\n         'Fireplaces','2ndFlrSF','BsmtQual','1stFlrSF','GarageArea','YearBuilt','TotalBsmtSF','FullBath','KitchenQual',\n         'GrLivArea','ExterQual','GarageCars','OverallQual'\n       ]]\ny=train[['SalePrice']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1=train[['BedroomAbvGr', 'GarageType','CentralAir','LotArea','YearRemodAdd','TotRmsAbvGrd','BsmtFinSF1',\n         'Fireplaces','2ndFlrSF','BsmtQual','1stFlrSF','GarageArea','YearBuilt','TotalBsmtSF','FullBath',\n          'KitchenQual','GrLivArea','ExterQual','GarageCars','OverallQual']]\ny1=train[['SalePrice']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_new=test[['BedroomAbvGr', 'GarageType','CentralAir','LotArea','YearRemodAdd','TotRmsAbvGrd','BsmtFinSF1','1stFlrSF',\n       'GarageArea','YearBuilt','TotalBsmtSF','FullBath','KitchenQual','GrLivArea','ExterQual','GarageCars','OverallQual',\n       'Fireplaces','2ndFlrSF','BsmtQual']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**using XGBoost**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using XGBoost\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\ndata_dmatrix = xgb.DMatrix(data=X,label=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_reg.fit(train_X,train_y,eval_set=[(train_X, train_y), (test_X, test_y)],eval_metric='logloss',verbose=True)\n\npreds = xg_reg.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evals_result = xg_reg.evals_result()\nevals_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(test_y, preds))\nprint(\"RMSE: %f\" % (rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#k-fold Cross Validation using XGBoost\nparams = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n                'max_depth': 5, 'alpha': 10}\n\ncv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n                    num_boost_round=50,early_stopping_rounds=10,metrics=\"mae\", as_pandas=True, seed=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print((cv_results[\"test-mae-mean\"]).tail(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize Boosting Trees and Feature Importance\nxg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nxgb.plot_tree(xg_reg,num_trees=0)\nplt.rcParams['figure.figsize'] = [200, 50]\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df=pd.DataFrame(preds,columns=['SalePrice'],index=None)\npreds_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import neptune","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Using LightGBM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nimport lightgbm as lgb\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport haversine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = X.columns.tolist()\n\n#test train split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=20)\nX_train.shape\n\n#creating lightGBM dataset\nlgtrain = lgb.Dataset(X_train, y_train,\n                feature_name=feature_names)\nlgvalid = lgb.Dataset(X_test, y_test,\n                feature_name=feature_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LightGBM Hyperparameters + early stopping\ngbm = lgb.LGBMRegressor(learning_rate = 0.15, metric = 'l1', \n                        n_estimators = 28,boosting_type='gbdt', objective='regression',max_bin=1000000)\n\n\ngbm.fit(X_train, y_train,\n        eval_set=[(X_test, y_test)],\n        eval_metric=['auc', 'l1'],\nearly_stopping_rounds=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import neptune\n\nneptune.init('priya-pathak/sandbox',\n             api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiOGMwMTIzYzktZDNlNi00NzA5LWI5MDMtNjRhZDFkMTIzODc1In0=')\nneptune.create_experiment()\n\ndef neptune_monitor():\n    def callback(env):\n        for name, loss_name, loss_value, _ in env.evaluation_result_list:\n            neptune.send_metric('{}_{}'.format(name, loss_name), x=env.iteration, y=loss_value)\n    return callback","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'objective' : 'regression_l1',\n    'boosting':'dart',\n    'metric' : 'rmse',\n    'num_leaves' : 300,\n    'max_depth': 20,\n    'learning_rate' : 0.1,\n    'feature_fraction' : 0.8,\n    'verbosity' : 1,\n    'num_iteratios':10000,\n    'num_threads':2,\n    'lambda_l1': 3.097758978478437,\n    'lambda_l2': 2.9482537987198496,\n    'min_child_weight': 6.996211413900573,\n    'min_split_gain': 0.037310344962162616\n    \n    \n}\nlgb_clf = lgb.train(\n    params,\n    lgtrain,\n    num_boost_round = 1000,\n    valid_sets=[lgtrain, lgvalid],\n    valid_names=[\"train\", \"valid\"],\n    early_stopping_rounds=1000,\n    callbacks=[neptune_monitor()]\n)\n\nprint(\"MAPE of the validation set:\", np.sqrt(mean_squared_error(y_test, lgb_clf.predict(X_test))))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 7))\nlgb.plot_importance(lgb_clf, max_num_features=30, ax=ax)\nplt.title(\"LightGBM - Feature Importance\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting data\ny_pred = gbm.predict(test_new,num_iteration=gbm.best_iteration_)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df1=pd.DataFrame(y_pred,columns=['SalePrice'],index=None)\npreds_df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\ntest1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([test1[['Id']], pd.DataFrame(preds_df1,columns=['SalePrice'])], axis=1)\n#submission=preds_df1\nsubmission.to_csv('submission_lightGBM4.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}